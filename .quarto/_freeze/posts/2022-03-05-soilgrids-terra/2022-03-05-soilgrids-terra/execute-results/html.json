{
  "hash": "1d4f4571ff5b88ade6844a670c066884",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Accessing SoilGrids via {terra}'\ndate: '2022-03-05'\ncategories: [R, soil erosion]\ncode-fold: show\ncode-summary: \"Show the code\"\n---\n\n\n\n\nAfter several `QGIS` and `R` packages updates, I cannot download [SoilGrids](https://www.isric.org/explore/soilgrids) with `rgdal` anymore.  When I'm trying to run code from [SoilGrids WebDAV tutorial](https://git.wur.nl/isric/soilgrids/soilgrids.notebooks/-/blob/master/markdown/webdav_from_R.md) I am receiving a following error:\n\n> `ERROR 11: CURL error: SSL certificate problem: unable to get local issuer certificate`\n\nI never managed to fix this issue, so I decided to let it go. Here is my approach to downloading cropped and reprojected SoilGrids raster. There was a really great [tutorial](https://rpubs.com/ials2un/soilgrids_webdav) by Ivan Lizarazo on getting several SoilGrids layers using `rgdal`. My approach is mostly based on it.\n\n### 1. Boundary layer\nFirst of all, let's load some boundary layer, i.e., our area of interest (AOI). I will use the default `sf` sample data for North Carolina counties. To reduce the size of AOI, let me select only the first county. The SoilGrids files are stored in Interrupted Goode Homolosine, so I have to reproject our AOI polygon to it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(sf)\n\n# Load sample data\nnc <- st_read(\n  system.file(\"shape/nc.shp\",\n    package = \"sf\"\n  ),\n  quiet = T\n) %>%\n  slice(1)\n\n# Transform to IGH projection\nigh <- \"+proj=igh +lat_0=0 +lon_0=0 +datum=WGS84 +units=m +no_defs\"\nnc_igh <- st_transform(nc, igh)\n```\n:::\n\n\n### 2. Download urls\nNow Let's just copy download urls from previous [tutorials](https://rpubs.com/ials2un/soilgrids_webdav). And create a link to every other separate `.vrt` file, since we are gonna `purrr::map` them later. I'm interested only in mean topsoil characteristics (i.e. 0-30 cm) right now. So I will download sand, silt, and clay content and soil organic carbon content (soc).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsg_url <- \"/vsicurl/https://files.isric.org/soilgrids/latest/data/\"\nprops <- c(\"sand\", \"silt\", \"clay\", \"soc\")\nlayers <- c(\"0-5\", \"5-15\", \"15-30\")\n\nvrt <- paste0(\n  props, \"/\",\n  props, \"_\",\n  rep(layers, 4),\n  \"cm_mean.vrt\"\n)\n\nvrt[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"sand/sand_0-5cm_mean.vrt\"\n```\n\n\n:::\n:::\n\n\nThen, we need to create a list of paths to save. Let's create a directory `soilgrid` where we are going to download our layers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Optional\n# Check if the directory exists\nif (!dir.exists(\"soilgrid\")) {\n  dir.create(\"soilgrid\")\n}\n\n\n# Create paths\nlfile <- paste0(\n  \"soilgrid/\",\n  props, \"_\",\n  rep(layers, 4),\n  \".tif\"\n)\n\nlfile[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"soilgrid/sand_0-5.tif\"\n```\n\n\n:::\n:::\n\n\n### 3. Download and preprocess function\nMy general idea is to crop the SoilGrid layer to the bounding box, reproject to my CRS (i.e. CRS of the `nc` layer), download, and then write as `.tif`. However, I want to do this for 12 rasters. Therefore, we need to write a function we are going to apply:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(terra)\n\n# Function to download and transform soilgrid layers\nsoilgrids_download <- function(list_vrt, # download url\n                               list_lfile, # destination path\n                               shape_igh, # AOI shape in IGH proj\n                               destproj) { # desired projection\n\n  terra::rast(paste0(sg_url, list_vrt)) %>% # read raster\n    terra::crop(ext(vect(shape_igh))) %>% # crop to bounding box\n    terra::project(destproj) %>% # reproject\n    terra::writeRaster(list_lfile,\n      overwrite = T\n    ) # Save\n}\n```\n:::\n\n\nBefore running it in the loop, let's try it for the first layer.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsoilgrids_download(\n  list_vrt = vrt[1],\n  list_lfile = lfile[1],\n  shape_igh = nc_igh,\n  destproj = st_crs(nc)$proj4string\n)\n\nrast(lfile[1]) %>%\n  plot()\n```\n\n::: {.cell-output-display}\n![](2022-03-05-soilgrids-terra_files/figure-html/unnamed-chunk-5-1.png){width=2400}\n:::\n:::\n\n\nIt worked!\n\n### 4. Map download\nNext, with the help of `purrr` we can apply this function to all our links. Let's measure elapsed time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)\nlibrary(tictoc)\n\ntic()\nwalk2(\n  vrt,\n  lfile,\n  ~ soilgrids_download(.x, .y,\n    shape_igh = nc_igh,\n    destproj = st_crs(nc)$proj4string\n  )\n)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n392.09 sec elapsed\n```\n\n\n:::\n:::\n\n\nWell, almost 2 mins. It is necessary to improve the timing somehow. This process can be run in parallel with `furrr`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(furrr)\n\n# Set Parallel\nno_cores <- availableCores() - 1\nplan(multisession,\n  workers = no_cores\n)\n\n# Download!\ntic()\nfuture_walk2(\n  vrt, lfile,\n  ~ soilgrids_download(.x, .y,\n    shape_igh = nc_igh,\n    destproj = st_crs(nc)$proj4string\n  )\n)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n63.44 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\n# Exit parallel\nplan(sequential)\n```\n:::\n\n\nLess than 1 minute. As [Josh Starmer](https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw) says, \"BAM!\". Three times faster! \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist.files(\"soilgrid\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"clay_0-5.tif\"   \"clay_15-30.tif\" \"clay_5-15.tif\"  \"sand_0-5.tif\"  \n [5] \"sand_15-30.tif\" \"sand_5-15.tif\"  \"silt_0-5.tif\"   \"silt_15-30.tif\"\n [9] \"silt_5-15.tif\"  \"soc_0-5.tif\"    \"soc_15-30.tif\"  \"soc_5-15.tif\"  \n```\n\n\n:::\n:::\n",
    "supporting": [
      "2022-03-05-soilgrids-terra_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}