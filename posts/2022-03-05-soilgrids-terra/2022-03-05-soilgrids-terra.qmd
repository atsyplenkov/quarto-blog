---
title: 'Accessing SoilGrids via {terra}'
author: 'Anatoly Tsyplenkov'
date: '2022-03-05'
categories: [R, soil erosion]
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  #cache = TRUE,
  warning = FALSE,
  message = FALSE, 
  echo = TRUE,
  dpi = 300,
  cache.lazy = FALSE,
  tidy = "styler",
  fig.width = 8,
  fig.height = 5)
```

After several `QGIS` and `R` packages updates, I cannot download [SoilGrids](https://www.isric.org/explore/soilgrids) with `rgdal` anymore.  When I'm trying to run code from [SoilGrids WebDAV tutorial](https://git.wur.nl/isric/soilgrids/soilgrids.notebooks/-/blob/master/markdown/webdav_from_R.md) I am receiving a following error:

> `ERROR 11: CURL error: SSL certificate problem: unable to get local issuer certificate`

I never managed to fix this issue, so I decided to let it go since everyone is slowly quitting GDAL anyway. Here is my approach to downloading cropped and reprojected SoilGrids raster. There was a really great [tutorial](https://rpubs.com/ials2un/soilgrids_webdav) by Ivan Lizarazo on getting several SoilGrids layers using `rgdal`. My approach is mostly based on it.

### 1. Boundary layer
First of all, let's load some boundary layer, i.e., our area of interest (AOI). I will use the default `sf` sample data for North Carolina counties. To reduce the size of AOI, let me select only the first county. The SoilGrids files are stored in Interrupted Goode Homolosine, so I have to reproject our AOI polygon to it.

```{r}
library(dplyr)
library(sf)

# Load sample data
nc <-  st_read(system.file("shape/nc.shp",
                         package = "sf"),
               quiet = T) %>% 
  slice(1)

# Transform to IGH projection
igh <- '+proj=igh +lat_0=0 +lon_0=0 +datum=WGS84 +units=m +no_defs'
nc_igh <- st_transform(nc, igh)

```

### 2. Download urls
Now Let's just copy download urls from previous [tutorials](https://rpubs.com/ials2un/soilgrids_webdav). And create a link to every other separate `.vrt` file, since we are gonna `purrr::map` them later. I'm interested only in mean topsoil characteristics (i.e. 0-30 cm) right now. So I will download sand, silt, and clay content and soil organic carbon content (soc).

```{r}
sg_url <- "/vsicurl/https://files.isric.org/soilgrids/latest/data/"
props <- c("sand", "silt", "clay", "soc")
layers <- c("0-5", "5-15", "15-30")

vrt <- paste0(props, "/",
               props, "_",
               rep(layers, 4),
               "cm_mean.vrt")

vrt[1]
```

Then, we need to create a list of paths to save. Let's create a directory `soilgrid` where we are going to download our layers.

```{r}
# Optional
# Check if the directory exists
if (!dir.exists("soilgrid")) {dir.create("soilgrid")}


# Create paths
lfile <- paste0(
  "soilgrid/",
  props, "_",
  rep(layers, 4),
  ".tif")

lfile[1]
```

### 3. Download and preprocess function
My general idea is to crop the SoilGrid layer to the bounding box, reproject to my CRS (i.e. CRS of the `nc` layer), download, and then write as `.tif`. However, I want to do this for `r length(lfile)` rasters. Therefore, we need to write a function we are going to apply:

```{r warning=FALSE, message=FALSE}
library(terra)

# Function to download and transform soilgrid layers
soilgrids_download <- function(list_vrt, # download url
                               list_lfile, # destination path
                               shape_igh, # AOI shape in IGH proj
                               destproj){ # desired projection
  
  terra::rast(paste0(sg_url, list_vrt)) %>% # read raster
    terra::crop(ext(vect(shape_igh))) %>%  # crop to bounding box
    terra::project(destproj) %>%  # reproject
    terra::writeRaster(list_lfile,
                       overwrite = T) # Save
  
}
```

Before running it in the loop, let's try it for the first layer.

```{r}

soilgrids_download(list_vrt = vrt[1],
                   list_lfile = lfile[1],
                   shape_igh = nc_igh,
                   destproj = st_crs(nc)$proj4string)

rast(lfile[1]) %>% 
  plot()
```

It worked!

### 4. Map download
Next, with the help of `purrr` we can apply this function to all our links. Let's measure elapsed time.

```{r}
library(purrr)
library(tictoc)

tic()
walk2(vrt,
      lfile,
      ~soilgrids_download(.x, .y,
                          shape_igh = nc_igh,
                          destproj = st_crs(nc)$proj4string))
toc()

```

Well, almost 2 mins. It is necessary to improve the timing somehow. This process can be run in parallel with `furrr`.

```{r}
library(furrr)

# Set Parallel
no_cores <- availableCores() - 1
plan(multisession,
     workers = no_cores) 

# Download!
tic()
future_walk2(vrt, lfile,
             ~soilgrids_download(.x, .y,
                          shape_igh = nc_igh,
                          destproj = st_crs(nc)$proj4string))
toc()

# Exit parallel
plan(sequential)

```

Less than 1 minute. As [Josh Starmer](https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw) says, "BAM!". Three times faster! 

```{r}

list.files("soilgrid")

```

